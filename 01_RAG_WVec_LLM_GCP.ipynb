{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcbjrrr/genai/blob/main/01_RAG_WVec_LLM_GCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (NLP)"
      ],
      "metadata": {
        "id": "wdN7Z6XB1FJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings and Tokenization"
      ],
      "metadata": {
        "id": "WbQ8GPIjwva5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2644f2c8"
      },
      "source": [
        "Natural Language Processing (NLP) is a field dedicated to enabling computers to understand, interpret, and generate human language. A cornerstone of modern NLP is the use of **embeddings**, which are numerical representations of words or phrases that capture their semantic meaning, allowing algorithms to process linguistic data effectively. Building upon these foundations, **Large Language Models (LLMs)** represent a significant advancement, utilizing vast datasets and sophisticated architectures to understand context, generate coherent text, and perform a wide array of language-based tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "heh-V8hFl-oc",
        "outputId": "83a050d7-8a09-4f58-88e3-0221aee11274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is a technique used in natural language processing to generate word embeddings. It represents words as dense vectors in a continuous vector space, where words with similar meanings are located closer to each other. This is achieved by analyzing the context in which words appear in a large corpus of text."
      ],
      "metadata": {
        "id": "AGihe2Hx1A_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from gensim.models import KeyedVectors\n",
        "word_vectors = KeyedVectors.load_word2vec_format(\"http://wikipedia2vec.s3.amazonaws.com/models/en/2018-04-20/enwiki_20180420_100d.txt.bz2\", binary=False,unicode_errors='ignore' )"
      ],
      "metadata": {
        "id": "CN5qb7fQmA6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embeddings** are numerical representations of real-world objects, such as words, images, or entire documents. In the context of natural language processing, word embeddings are vectors that capture semantic relationships between words, allowing algorithms to process and understand human language more effectively.\n",
        "\n",
        "![](https://towardsdatascience.com/wp-content/uploads/2020/06/1HOvcH2lZXWyOtmcqwniahQ.png)"
      ],
      "metadata": {
        "id": "82Kpimu7xMCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed = word_vectors['generative']\n",
        "embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbnNLOtymQ5P",
        "outputId": "579b4b6d-5f9d-44cb-c24d-8d187d67b000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.1944,  0.3173, -0.6029, -0.2289, -0.159 , -0.6233,  0.1637,\n",
              "        0.4812,  0.3664, -0.4371,  0.4014,  0.356 , -0.4489, -0.1209,\n",
              "        0.1787, -0.4777,  0.4284, -0.5101,  0.574 , -0.4029,  0.2346,\n",
              "        0.0616, -0.5732, -0.5495,  0.0648, -0.5697,  0.3056,  0.0199,\n",
              "        0.4866,  0.5387,  0.1568,  0.2029,  0.9879,  0.3328,  0.6987,\n",
              "        0.314 , -0.271 , -0.2186,  0.2244,  0.0273, -0.1938,  0.2384,\n",
              "       -0.3099,  0.5102,  0.2235, -0.1594, -0.8178, -0.014 , -0.4044,\n",
              "        0.1803,  0.2592,  0.1052, -0.0816,  0.06  , -0.0441, -0.3898,\n",
              "       -0.6213,  0.2516, -0.2886,  0.7391, -0.2618,  0.4155, -0.4727,\n",
              "        0.785 ,  0.7197, -0.0754, -0.4997,  0.1545, -0.8258, -0.7265,\n",
              "        0.3349,  0.1798, -0.5484, -0.2569,  0.0863, -0.4086, -0.8779,\n",
              "        0.3763,  0.3226,  0.641 , -1.3968,  0.0903,  0.3317, -0.7599,\n",
              "       -0.1855,  0.7091, -0.2894, -0.1777,  0.3832, -0.3214,  0.0448,\n",
              "       -0.0806, -0.5196,  0.3394,  0.4149, -0.3964,  0.5066,  0.3642,\n",
              "       -0.3679,  0.2436], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.most_similar(\"generative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6KScrn_mf31",
        "outputId": "0db99b05-00f3-455a-bfe9-05a389add7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lexicalist', 0.779882550239563),\n",
              " ('chomskyan', 0.7596522569656372),\n",
              " ('connectivist', 0.7340349555015564),\n",
              " ('neuroaesthetics', 0.729445219039917),\n",
              " ('generativist', 0.7284153699874878),\n",
              " ('homuncular', 0.7270619869232178),\n",
              " ('ENTITY/Glue_semantics', 0.7268419861793518),\n",
              " ('meinongian', 0.7229824066162109),\n",
              " ('metasystems', 0.720165491104126),\n",
              " ('ENTITY/Constraint-based_grammar', 0.7194753289222717)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokens** are the fundamental building blocks of text data in natural language processing. They are discrete units derived from a larger body of text, typically words, punctuation marks, or subword units (like 'ing' or 'un'). This process of breaking down text into tokens is called tokenization and is a crucial first step for most NLP tasks, as models often operate on these individual tokens rather than raw text."
      ],
      "metadata": {
        "id": "MZ5Ti8ByykFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def calc_embeddings(tokens):\n",
        "  #the mean of the words in the sentence as the vector rep of it\n",
        "  return  np.mean(np.array([word_vectors[t] for t in tokens if t in word_vectors.key_to_index]), axis=0)"
      ],
      "metadata": {
        "id": "zdNMbrovn1eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['IA: Artificial Intelligence is the broad, overarching field dedicated to creating machines that can simulate human intelligence and perform tasks like reasoning and problem-solving.',\n",
        "'ML: Machine Learning is a subset of AI where systems learn from data to identify patterns and make predictions without being explicitly programmed for every task.',\n",
        "'DL: Deep Learning is a specialized form of ML that uses deep neural networks, inspired by the human brain, to automatically process complex, unstructured data like images, audio, and language.',\n",
        "'GenAI: Generative AI is a branch of AI and type of DL model specifically designed to create new, original content, such as text, images, or code, based on the patterns it learned during training.',\n",
        "'LLMs: Large Language Models are a specific and prominent type of generative AI model that are trained on vast amounts of text data to understand, interpret, and generate human-like language.']"
      ],
      "metadata": {
        "id": "DdGDNt4Dn213"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0])\n",
        "tokens = sentences[0].split(' ')\n",
        "print(tokens)\n",
        "calc_embeddings(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW-0b4qssZRT",
        "outputId": "a41490c0-a7cf-4d1c-8217-65a20ff927cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IA: Artificial Intelligence is the broad, overarching field dedicated to creating machines that can simulate human intelligence and perform tasks like reasoning and problem-solving.\n",
            "['Artificial', 'Intelligence', 'is', 'the', 'broad,', 'overarching', 'field', 'dedicated', 'to', 'creating', 'machines', 'that', 'can', 'simulate', 'human', 'intelligence', 'and', 'perform', 'tasks', 'like', 'reasoning', 'and', 'problem-solving.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01807368,  0.16352107, -0.15188423,  0.07623159, -0.08888421,\n",
              "       -0.20527896,  0.10365262,  0.02830527,  0.11858946, -0.22463684,\n",
              "        0.04217368, -0.20571578,  0.19375263, -0.14140527,  0.32829472,\n",
              "       -0.33084735, -0.06887895, -0.26750526, -0.00831579, -0.02776317,\n",
              "       -0.05177368, -0.01493158, -0.09573158,  0.04466842, -0.17360526,\n",
              "       -0.2861684 , -0.20236316, -0.1854579 ,  0.19154736,  0.39044213,\n",
              "        0.25146842,  0.03066842,  0.02402631,  0.29369473,  0.16242105,\n",
              "       -0.12049475, -0.01683684, -0.05483686,  0.18093683, -0.0306    ,\n",
              "        0.00796316,  0.03291053, -0.21464737,  0.03662105, -0.1074    ,\n",
              "       -0.28423157, -0.10834736,  0.14964211, -0.2059    , -0.02927895,\n",
              "       -0.15419473,  0.16150525,  0.00641578,  0.16225262,  0.07394737,\n",
              "       -0.02751579, -0.23002635, -0.04693684, -0.05505789,  0.21131054,\n",
              "       -0.14008947, -0.13240527, -0.24106315,  0.22333685,  0.49372637,\n",
              "       -0.25698423, -0.3175947 , -0.2712526 , -0.23358947, -0.4244158 ,\n",
              "       -0.00936842,  0.27174208, -0.03191053,  0.32100525, -0.2965263 ,\n",
              "       -0.17022106, -0.3980526 ,  0.21701053, -0.13064212, -0.0524579 ,\n",
              "       -0.14345789, -0.27037895,  0.27941054, -0.21287896,  0.20498422,\n",
              "        0.5392369 ,  0.10846841,  0.18764737,  0.3376842 ,  0.0451    ,\n",
              "       -0.00283684,  0.00303684,  0.1288158 , -0.07704738,  0.0891158 ,\n",
              "       -0.08294211,  0.17715259,  0.29312107, -0.3290316 , -0.01999474],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.array([calc_embeddings(v.split(' ')) for v in sentences])\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoTYCHr1tgcd",
        "outputId": "b00d0994-c309-480f-f3c1-2dfecbf36d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Clustering* is a machine learning technique that groups similar data points together into clusters, such that items within a cluster are more similar to each other than to those in other clusters."
      ],
      "metadata": {
        "id": "0t3MoqwD0RCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=3 )\n",
        "clusters = kmeans.fit_predict(embeddings)\n",
        "for i in range(0,5,1):\n",
        "  print(clusters[i],sentences[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgajnp_Iumgw",
        "outputId": "3a2ded81-3050-456e-d774-983730c33ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 Artificial Intelligence is the broad, overarching field dedicated to creating machines that can simulate human intelligence and perform tasks like reasoning and problem-solving.\n",
            "0 Machine Learning is a subset of AI where systems learn from data to identify patterns and make predictions without being explicitly programmed for every task.\n",
            "0 Deep Learning is a specialized form of ML that uses deep neural networks, inspired by the human brain, to automatically process complex, unstructured data like images, audio, and language.\n",
            "1 Generative AI is a branch of AI and type of DL model specifically designed to create new, original content, such as text, images, or code, based on the patterns it learned during training.\n",
            "1 Large Language Models (LLMs) are a specific and prominent type of generative AI model that are trained on vast amounts of text data to understand, interpret, and generate human-like language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Principal Component Analysis (PCA)* is a dimensionality reduction technique that transforms a dataset of possibly correlated variables into a smaller set of uncorrelated variables called principal components, while retaining as much of the original variability as possible."
      ],
      "metadata": {
        "id": "9HUQnmN_0aau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "reduc_embe = pca.fit_transform(embeddings)\n",
        "print(reduc_embe)\n",
        "i=0\n",
        "for v in [o.split(':')[0] for o in sentences]:\n",
        "  plt.text(reduc_embe[i, 0], reduc_embe[i, 1], v, fontsize=9, ha='left')\n",
        "  i=i+1\n",
        "plt.scatter(x=reduc_embe[:, 0], y=reduc_embe[:, 1], c=clusters,cmap='Set1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "ILtYFrbvusNU",
        "outputId": "6923f601-7cd8-4314-a102-2f4d9328e108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.46062785  0.18003269]\n",
            " [ 0.09294321 -0.11400206]\n",
            " [ 0.01019943 -0.26278165]\n",
            " [-0.3135061   0.32276726]\n",
            " [-0.25026438 -0.12601623]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7cb168fe1700>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GenAI: LLMs"
      ],
      "metadata": {
        "id": "lspfbHXR4Ej1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI represents a significant advancement, allowing the creation of original and diverse content, such as texts, images, and audio, promising to transform industries by automating creative processes and offering new tools for innovation. The training of these models is based on exposure to vast amounts of data relevant to the desired content, using neural network architectures. Furthermore, the process of creating and refining the inputs provided to a language model to obtain desired responses is crucial for effectively directing the generative capacity of AI.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G5XShNuWsAA_sWo?format=jpg&name=medium)"
      ],
      "metadata": {
        "id": "P886931M2GmJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ae22d2d"
      },
      "source": [
        "Large Language Models (LLMs) are a highly advanced class of generative AI models built upon the principles of **Deep Learning**. They primarily utilize sophisticated **neural networks**, which are computational architectures inspired by the human brain, characterized by multiple layers that enable them to learn complex patterns from data. The most prevalent architecture within LLMs today is the **transformer** model, which excels at processing sequential data like text by employing attention mechanisms to weigh the importance of different parts of the input. This combination allows LLMs to process vast amounts of text, understand context, and generate human-like language for a wide array of tasks, from translation and summarization to creative writing and question answering.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G5XS8P4WUAAYvO2?format=jpg&name=medium)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In LLMs (especially Transformers):\n",
        "\n",
        "*   **Encoder:** Reads and understands the input text, converting it into a rich numerical representation.\n",
        "\n",
        "*   **Decoder:** Uses this representation to generate the output text, predicting one word at a time based on the input and previously generated words.\n",
        "\n",
        "Some LLMs are purely decoder-based but still perform these two core functions.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G5XTWbcWAAA85ry?format=jpg&name=medium)"
      ],
      "metadata": {
        "id": "t2EeDs8Z2wOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OLD"
      ],
      "metadata": {
        "id": "fi0cikLXebzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install google-generativeai\n",
        "# import google.generativeai as genai\n",
        "# import os\n",
        "\n",
        "# GCP_MODEL = 'gemini-2.5-flash'\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# model = genai.GenerativeModel(GCP_MODEL)\n",
        "\n",
        "# response = model.generate_content(\n",
        "#     contents=\"Explain large language models in one sentence.\"\n",
        "# )\n",
        "# print(response.text)"
      ],
      "metadata": {
        "id": "7NvRzMIzedwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OK"
      ],
      "metadata": {
        "id": "g8aS8XWpeeKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemini"
      ],
      "metadata": {
        "id": "FDY5CaHoeglf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-genai\n"
      ],
      "metadata": {
        "id": "kWYlymkoehzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GCP_MODEL = 'gemini-2.5-flash'\n",
        "GOOGLE_API_KEY = 'your key'\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "oExLCUOkemHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google import genai\n",
        "client = genai.Client()\n",
        "response = client.models.generate_content(\n",
        "    model=GCP_MODEL,\n",
        "    contents=\"Explain large language models in one sentence.\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "uOZ_1p8-eh-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install google-genai"
      ],
      "metadata": {
        "id": "phFRRd2-luxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "SYSTEM_INSTRUCTION = 'You are a GenAI expert. That will explain concepts to a layman audience'\n",
        "\n",
        "client = genai.Client()\n",
        "question='What is the difference from Deep Learning?'\n",
        "\n",
        "config = types.GenerateContentConfig(\n",
        "    system_instruction=SYSTEM_INSTRUCTION,\n",
        "    temperature=0.9,  #(0.0=deterministic, 2.0=highly creative)\n",
        "    max_output_tokens=1000)\n",
        "\n",
        "initial_history = [\n",
        "    types.Content(role=\"user\",parts=[types.Part(text=\"In a sentence, what are LLMs?\")]),\n",
        "    types.Content(role=\"model\",parts=[types.Part(text=\"LLMs are advanced AI systems trained on vast amounts of text data to understand prompts and generate human-like.\")])\n",
        "  ]\n",
        "\n",
        "chat = client.chats.create(\n",
        "        model=GCP_MODEL,\n",
        "        history=initial_history,\n",
        "        config=config)\n",
        "\n",
        "response = chat.send_message(question)\n",
        "print(f\"Model: {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJZrD4spy5eE",
        "outputId": "70744075-f0e5-4491-e6b3-2ac6a5724114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Deep Learning is the *broader set of techniques* (like an engine technology) that allows AI to learn complex patterns from data, while LLMs are a *specific, highly specialized type of AI model* (like a particular type of vehicle) that uses those deep learning techniques specifically to understand and generate human language.\n",
            "\n",
            "So, Deep Learning is the *how*, and LLMs are a *what* that uses that *how*.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLMs Orchestration"
      ],
      "metadata": {
        "id": "od8vMrfh1lGF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b853c36"
      },
      "source": [
        "**LangChain** significantly streamlines the development of Retrieval Augmented Generation (RAG) solutions by providing a structured framework to orchestrate its multiple steps. It simplifies the entire process by offering various connectors and components for each stage: from integrating with diverse data sources (databases, documents, APIs) and performing efficient data retrieval (using vector databases and sophisticated indexing techniques), to formulating intelligent prompts and seamlessly feeding the retrieved context into Large Language Models (LLMs) for generating coherent and contextually relevant responses. This modular approach allows developers to easily swap out components, experiment with different strategies, and build complex RAG pipelines with reduced boilerplate code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-core langchain-google-genai"
      ],
      "metadata": {
        "id": "lMWAFBuDI_Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "sys_msg = 'You are a GenAI expert. That will explain concepts to a layman audience'\n",
        "prompt_question = \"In a sentence, what is the difference from Deep Learning?\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", sys_msg),\n",
        "        (\"human\", \"In a sentence, what are LLMs\"),\n",
        "        (\"ai\", \"LLMs are advanced artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language.\"),\n",
        "        (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=GCP_MODEL,\n",
        "    temperature=0.9,\n",
        "    max_tokens=1000,\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Create the chain using the | operator\n",
        "chain = prompt_template | llm | output_parser\n",
        "\n",
        "response = chain.invoke({\"question\": prompt_question})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QDNiNNCHhkj",
        "outputId": "5b4387d9-fdae-4e56-80d2-e29fe4b9665e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Learning is a broader AI technique that uses complex, multi-layered networks to learn from data, while LLMs are a specific type of model built using this technique, specifically designed to process and generate human language.\n"
          ]
        }
      ]
    }
  ]
}