{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcbjrrr/genai/blob/main/00_RAG_NLP_GCPpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Phtwtbf5eA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fundamentos"
      ],
      "metadata": {
        "id": "skct5N00hxEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Natural Language Processing (NLP)"
      ],
      "metadata": {
        "id": "DHazxZdAiED1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Processamento de Linguagem Natural (NLP) é um campo multidisciplinar na interseção da ciência da computação, inteligência artificial (IA) e linguística. Seu objetivo principal é permitir que os computadores compreendam, interpretem e gerem linguagem humana de uma forma significativa e útil. Isso envolve o desenvolvimento de algoritmos e modelos para processar dados brutos de texto e fala, permitindo que as máquinas realizem tarefas como tradução, análise de sentimentos, sumarização de texto e assistentes de voz. O NLP é fundamental para a forma como as pessoas interagem com a tecnologia, tornando os sistemas mais intuitivos e capazes de lidar com a complexidade e as nuances da comunicação humana."
      ],
      "metadata": {
        "id": "CAi5srgIiIDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Neural Networks and Deep Learning"
      ],
      "metadata": {
        "id": "4cJpMa5xifIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A aprendizagem profunda, baseada em redes neurais e especificamente em Redes Neurais Recorrentes (RNNs), revolucionou o Processamento de Linguagem Natural (PLN) ao permitir que os computadores compreendam a natureza sequencial da linguagem humana. Variantes de RNN, como LSTM e GRUs, utilizam um estado oculto interno (memória) para manter o contexto ao longo de uma sequência de palavras, superando a limitação das redes neurais padrão. Essa capacidade permite que elas se destaquem em tarefas sequenciais, como tradução automática (usando modelos codificador-decodificador), modelagem de linguagem para geração de texto e análise de sentimentos. Embora a arquitetura Transformer mais recente tenha se tornado dominante, as RNNs estabeleceram a base crucial da aprendizagem profunda para lidar com a complexidade, o contexto e as dependências inerentes aos dados textuais.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G55BA6oXIAA4x_y?format=jpg&name=900x900)"
      ],
      "metadata": {
        "id": "oaSIU4q8ivmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Feedforward Neural Network (FNN)"
      ],
      "metadata": {
        "id": "ijD10UByjeAM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6f57863"
      },
      "source": [
        "Uma rede neural de alimentação direta, frequentemente chamada de Rede Neural Feedforward (FNN), é o tipo mais simples de rede neural artificial. Em uma FNN, a informação se move em apenas uma direção — para frente — da camada de entrada, passando por quaisquer camadas ocultas, e finalmente chegando à camada de saída. Não há loops ou ciclos, o que significa que os dados fluem linearmente sem retornar ao início, tornando-as adequadas para tarefas como classificação e regressão, onde a entrada é mapeada diretamente para uma saída.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G55BMjMWwAAFIVf?format=png&name=360x360)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Networks (RNNs)"
      ],
      "metadata": {
        "id": "HYKeVK_Rkgar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma Rede Neural Recorrente (RNN) é um tipo de rede neural projetada especificamente para processar dados sequenciais, como texto, fala ou séries temporais. Ao contrário das Redes Feedforward, as RNNs possuem um loop que permite a passagem de informações de uma etapa da rede para a seguinte, efetivamente conferindo-lhes uma memória interna ou estado oculto. Essa memória permite que a rede considere o contexto dos elementos anteriores em uma sequência ao processar o elemento atual. Isso torna as RNNs particularmente adequadas para tarefas como processamento de linguagem natural (PLN), onde o significado de uma palavra depende fortemente das palavras que a precedem, permitindo que elas executem tarefas dependentes de sequência, como modelagem de linguagem e tradução automática.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G55B_46WMAA12ts?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "intJ8Hiik6Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "text = \"Deep learning, based on neural networks and specifically Recurrent Neural Networks (RNNs), revolutionized Natural Language Processing (NLP)\"\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "index_to_char = {i: char for i, char in enumerate(chars)}\n",
        "char_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7Gfp9il92x",
        "outputId": "75d1b3a8-1433-4c54-a6a6-48657787184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '(': 1,\n",
              " ')': 2,\n",
              " ',': 3,\n",
              " 'D': 4,\n",
              " 'L': 5,\n",
              " 'N': 6,\n",
              " 'P': 7,\n",
              " 'R': 8,\n",
              " 'a': 9,\n",
              " 'b': 10,\n",
              " 'c': 11,\n",
              " 'd': 12,\n",
              " 'e': 13,\n",
              " 'f': 14,\n",
              " 'g': 15,\n",
              " 'i': 16,\n",
              " 'k': 17,\n",
              " 'l': 18,\n",
              " 'n': 19,\n",
              " 'o': 20,\n",
              " 'p': 21,\n",
              " 'r': 22,\n",
              " 's': 23,\n",
              " 't': 24,\n",
              " 'u': 25,\n",
              " 'v': 26,\n",
              " 'w': 27,\n",
              " 'y': 28,\n",
              " 'z': 29}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = text[0:0 + 3]\n",
        "label = text[3]\n",
        "print(seq,([char_to_index[char] for char in seq]))\n",
        "print(label,char_to_index[label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbBlpkMGnpuX",
        "outputId": "a0cc284e-202f-452a-f826-753363f73a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dee [4, 13, 13]\n",
            "p 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 3\n",
        "sequences = []\n",
        "labels = []\n",
        "for i in range(len(text) - seq_length):\n",
        "    seq = text[i:i + seq_length]\n",
        "    label = text[i + seq_length]\n",
        "    sequences.append([char_to_index[char] for char in seq])\n",
        "    labels.append(char_to_index[label])\n",
        "\n",
        "X = np.array(sequences)\n",
        "y = np.array(labels)\n",
        "print(y)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcPIXBHtmdQH",
        "outputId": "b22f0e05-428e-46d8-c0de-546f5a019690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21  0 18 13  9 22 19 16 19 15  3  0 10  9 23 13 12  0 20 19  0 19 13 25\n",
            " 22  9 18  0 19 13 24 27 20 22 17 23  0  9 19 12  0 23 21 13 11 16 14 16\n",
            " 11  9 18 18 28  0  8 13 11 25 22 22 13 19 24  0  6 13 25 22  9 18  0  6\n",
            " 13 24 27 20 22 17 23  0  1  8  6  6 23  2  3  0 22 13 26 20 18 25 24 16\n",
            " 20 19 16 29 13 12  0  6  9 24 25 22  9 18  0  5  9 19 15 25  9 15 13  0\n",
            "  7 22 20 11 13 23 23 16 19 15  0  1  6  5  7  2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 13, 13],\n",
              "       [13, 13, 21],\n",
              "       [13, 21,  0],\n",
              "       [21,  0, 18],\n",
              "       [ 0, 18, 13],\n",
              "       [18, 13,  9],\n",
              "       [13,  9, 22],\n",
              "       [ 9, 22, 19],\n",
              "       [22, 19, 16],\n",
              "       [19, 16, 19],\n",
              "       [16, 19, 15],\n",
              "       [19, 15,  3],\n",
              "       [15,  3,  0],\n",
              "       [ 3,  0, 10],\n",
              "       [ 0, 10,  9],\n",
              "       [10,  9, 23],\n",
              "       [ 9, 23, 13],\n",
              "       [23, 13, 12],\n",
              "       [13, 12,  0],\n",
              "       [12,  0, 20],\n",
              "       [ 0, 20, 19],\n",
              "       [20, 19,  0],\n",
              "       [19,  0, 19],\n",
              "       [ 0, 19, 13],\n",
              "       [19, 13, 25],\n",
              "       [13, 25, 22],\n",
              "       [25, 22,  9],\n",
              "       [22,  9, 18],\n",
              "       [ 9, 18,  0],\n",
              "       [18,  0, 19],\n",
              "       [ 0, 19, 13],\n",
              "       [19, 13, 24],\n",
              "       [13, 24, 27],\n",
              "       [24, 27, 20],\n",
              "       [27, 20, 22],\n",
              "       [20, 22, 17],\n",
              "       [22, 17, 23],\n",
              "       [17, 23,  0],\n",
              "       [23,  0,  9],\n",
              "       [ 0,  9, 19],\n",
              "       [ 9, 19, 12],\n",
              "       [19, 12,  0],\n",
              "       [12,  0, 23],\n",
              "       [ 0, 23, 21],\n",
              "       [23, 21, 13],\n",
              "       [21, 13, 11],\n",
              "       [13, 11, 16],\n",
              "       [11, 16, 14],\n",
              "       [16, 14, 16],\n",
              "       [14, 16, 11],\n",
              "       [16, 11,  9],\n",
              "       [11,  9, 18],\n",
              "       [ 9, 18, 18],\n",
              "       [18, 18, 28],\n",
              "       [18, 28,  0],\n",
              "       [28,  0,  8],\n",
              "       [ 0,  8, 13],\n",
              "       [ 8, 13, 11],\n",
              "       [13, 11, 25],\n",
              "       [11, 25, 22],\n",
              "       [25, 22, 22],\n",
              "       [22, 22, 13],\n",
              "       [22, 13, 19],\n",
              "       [13, 19, 24],\n",
              "       [19, 24,  0],\n",
              "       [24,  0,  6],\n",
              "       [ 0,  6, 13],\n",
              "       [ 6, 13, 25],\n",
              "       [13, 25, 22],\n",
              "       [25, 22,  9],\n",
              "       [22,  9, 18],\n",
              "       [ 9, 18,  0],\n",
              "       [18,  0,  6],\n",
              "       [ 0,  6, 13],\n",
              "       [ 6, 13, 24],\n",
              "       [13, 24, 27],\n",
              "       [24, 27, 20],\n",
              "       [27, 20, 22],\n",
              "       [20, 22, 17],\n",
              "       [22, 17, 23],\n",
              "       [17, 23,  0],\n",
              "       [23,  0,  1],\n",
              "       [ 0,  1,  8],\n",
              "       [ 1,  8,  6],\n",
              "       [ 8,  6,  6],\n",
              "       [ 6,  6, 23],\n",
              "       [ 6, 23,  2],\n",
              "       [23,  2,  3],\n",
              "       [ 2,  3,  0],\n",
              "       [ 3,  0, 22],\n",
              "       [ 0, 22, 13],\n",
              "       [22, 13, 26],\n",
              "       [13, 26, 20],\n",
              "       [26, 20, 18],\n",
              "       [20, 18, 25],\n",
              "       [18, 25, 24],\n",
              "       [25, 24, 16],\n",
              "       [24, 16, 20],\n",
              "       [16, 20, 19],\n",
              "       [20, 19, 16],\n",
              "       [19, 16, 29],\n",
              "       [16, 29, 13],\n",
              "       [29, 13, 12],\n",
              "       [13, 12,  0],\n",
              "       [12,  0,  6],\n",
              "       [ 0,  6,  9],\n",
              "       [ 6,  9, 24],\n",
              "       [ 9, 24, 25],\n",
              "       [24, 25, 22],\n",
              "       [25, 22,  9],\n",
              "       [22,  9, 18],\n",
              "       [ 9, 18,  0],\n",
              "       [18,  0,  5],\n",
              "       [ 0,  5,  9],\n",
              "       [ 5,  9, 19],\n",
              "       [ 9, 19, 15],\n",
              "       [19, 15, 25],\n",
              "       [15, 25,  9],\n",
              "       [25,  9, 15],\n",
              "       [ 9, 15, 13],\n",
              "       [15, 13,  0],\n",
              "       [13,  0,  7],\n",
              "       [ 0,  7, 22],\n",
              "       [ 7, 22, 20],\n",
              "       [22, 20, 11],\n",
              "       [20, 11, 13],\n",
              "       [11, 13, 23],\n",
              "       [13, 23, 23],\n",
              "       [23, 23, 16],\n",
              "       [23, 16, 19],\n",
              "       [16, 19, 15],\n",
              "       [19, 15,  0],\n",
              "       [15,  0,  1],\n",
              "       [ 0,  1,  6],\n",
              "       [ 1,  6,  5],\n",
              "       [ 6,  5,  7]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_one_hot = tf.one_hot(X, len(chars))\n",
        "y_one_hot = tf.one_hot(y, len(chars))\n",
        "y_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRBM-ljFoaKN",
        "outputId": "8033aaba-c290-431b-b1e5-e50f622aaf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(136, 30), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(50, input_shape=(seq_length, len(chars)), activation='relu'))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_one_hot, y_one_hot, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKnwRc7sol-r",
        "outputId": "a0d9b7f6-e4e2-437a-b29f-a6f265efa776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.0322 - loss: 3.3939\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0627 - loss: 3.3707\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0759 - loss: 3.3413\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1398 - loss: 3.3054\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1632 - loss: 3.2834\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1688 - loss: 3.2704\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1570 - loss: 3.2450\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1886 - loss: 3.2034\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1708 - loss: 3.1863\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1996 - loss: 3.1462\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2039 - loss: 3.0843\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2440 - loss: 3.0271 \n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1639 - loss: 2.9933\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1463 - loss: 2.9951\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1754 - loss: 2.8851 \n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1558 - loss: 2.8205\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2151 - loss: 2.7603\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2028 - loss: 2.7071\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1692 - loss: 2.7098\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2162 - loss: 2.6589 \n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2240 - loss: 2.6193 \n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2756 - loss: 2.4928\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3058 - loss: 2.5187\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2982 - loss: 2.5087\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3593 - loss: 2.4216\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3472 - loss: 2.4269\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3662 - loss: 2.3484\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3322 - loss: 2.3598\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3779 - loss: 2.2443\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4026 - loss: 2.1863\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3970 - loss: 2.2460\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3764 - loss: 2.1855\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4444 - loss: 2.0782\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3983 - loss: 2.0827\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4241 - loss: 2.0226\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4431 - loss: 1.9171\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4167 - loss: 1.9122\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4812 - loss: 1.8869\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4777 - loss: 1.8088\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5166 - loss: 1.8460\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4979 - loss: 1.8248\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5366 - loss: 1.7086\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5434 - loss: 1.6490\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 1.6701\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5916 - loss: 1.6216\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5654 - loss: 1.6317\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6114 - loss: 1.5538\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5663 - loss: 1.5730\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5968 - loss: 1.4479\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6392 - loss: 1.4288\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5891 - loss: 1.4467\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6513 - loss: 1.4072\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 1.3623\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7129 - loss: 1.2516\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7075 - loss: 1.2256\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6988 - loss: 1.2746\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6987 - loss: 1.2383\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7176 - loss: 1.1769\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7238 - loss: 1.1764\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7370 - loss: 1.1165\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7298 - loss: 1.1048\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8109 - loss: 1.0144\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7585 - loss: 1.0425\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7951 - loss: 1.0182\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8172 - loss: 0.9575\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7899 - loss: 0.9698\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8017 - loss: 0.9261\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8360 - loss: 0.9122\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.9182\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8279 - loss: 0.9110\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8512 - loss: 0.8390\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8387 - loss: 0.8560\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8565 - loss: 0.7965\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8827 - loss: 0.7631\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8407 - loss: 0.7803\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8678 - loss: 0.7525\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8619 - loss: 0.7374\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8863 - loss: 0.6863\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8979 - loss: 0.7004\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.6730\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8981 - loss: 0.6758\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8944 - loss: 0.6072\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9166 - loss: 0.6169\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9130 - loss: 0.6061\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9121 - loss: 0.5891\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9129 - loss: 0.5908\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8990 - loss: 0.5529\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9011 - loss: 0.5610\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9270 - loss: 0.5465 \n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9118 - loss: 0.5191\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9295 - loss: 0.5356\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9166 - loss: 0.5190\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9240 - loss: 0.4875\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9292 - loss: 0.4910\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9360 - loss: 0.4847\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9123 - loss: 0.4950 \n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9387 - loss: 0.4844\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9474 - loss: 0.4675\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9254 - loss: 0.4582 \n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9312 - loss: 0.4250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3f986405c0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_seq = \"Deep learn\"\n",
        "generated_text = start_seq\n",
        "x = np.array([[char_to_index[char] for char in generated_text[-seq_length:]]])\n",
        "print(x)\n",
        "x_one_hot = tf.one_hot(x, len(chars))\n",
        "prediction = model.predict(x_one_hot)\n",
        "print(prediction)\n",
        "next_index = np.argmax(prediction)\n",
        "print('i=',next_index)\n",
        "index_to_char[next_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "GwidfmOMpDYr",
        "outputId": "67af4367-62b9-40eb-dd5a-973e2ad2fce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 22 19]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "[[4.1251425e-03 6.2324303e-05 2.2147446e-04 1.9480025e-03 1.2255202e-07\n",
            "  1.0490847e-03 6.5407349e-04 3.5293182e-04 2.2353372e-03 2.7259419e-04\n",
            "  1.2645606e-04 2.5162909e-03 1.0940621e-02 4.7563175e-03 6.1482824e-05\n",
            "  7.4091151e-02 7.3047072e-01 7.2677008e-06 6.4172670e-03 1.2773836e-01\n",
            "  2.9101330e-04 4.3879808e-03 1.4244112e-03 1.1509197e-02 8.1044408e-03\n",
            "  2.8423651e-03 2.0474964e-03 1.0588899e-04 4.6334579e-04 7.7690370e-04]]\n",
            "i= 16\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(60):\n",
        "    x = np.array([[char_to_index[char] for char in generated_text[-seq_length:]]])\n",
        "    x_one_hot = tf.one_hot(x, len(chars))\n",
        "    prediction = model.predict(x_one_hot)\n",
        "    next_index = np.argmax(prediction)\n",
        "    next_char = index_to_char[next_index]\n",
        "    generated_text += next_char\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvuB1te8qJ2c",
        "outputId": "04a54368-ed27-42c1-86cd-50128a22a2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Generated Text:\n",
            "Deep learning (NLP)urrent Networks and specifically Recurrent Networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T5 (Text-to-Text Transfer Transformer)"
      ],
      "metadata": {
        "id": "9bzucX34l88E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo T5 (Text-to-Text Transfer Transformer), desenvolvido pelo Google AI, revolucionou o PNL (Processamento de Linguagem Natural) ao introduzir uma estrutura unificada onde cada tarefa linguística é tratada como um problema de texto para texto. Construído sobre a estrutura codificador-decodificador da arquitetura Transformer, o T5 consegue lidar com diversas tarefas — incluindo tradução, sumarização, resposta a perguntas e classificação — simplesmente fornecendo à entrada um prefixo específico da tarefa (por exemplo, \"traduzir inglês para alemão: ...\") e recebendo a saída como texto simples. Essa consistência simplifica o design do modelo e permite que um único modelo pré-treinado alcance resultados de última geração em diversos benchmarks após o ajuste fino.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G55IpcfW8AAYrY4?format=png&name=360x360)"
      ],
      "metadata": {
        "id": "La3VVyFIrih8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os Transformers são uma arquitetura de rede neural poderosa que utiliza um **mecanismo de atenção** para ponderar a importância de diferentes partes dos dados de entrada, permitindo-lhes processar sequências em paralelo e capturar eficientemente dependências de longo alcance, tornando-se a base para modelos de linguagem modernos de grande escala como o BERT e o GPT.\n",
        "\n",
        "![](https://pbs.twimg.com/media/G55JZMnXAAAgub2?format=jpg&name=900x900)"
      ],
      "metadata": {
        "id": "jBPBg5ZasS3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers torch sentencepiece"
      ],
      "metadata": {
        "id": "LOirAkknstt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "model_name = \"t5-small\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "SwgYUN9Eripp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de linguagem T5 para tarefas de texto para texto. Importa os componentes necessários da biblioteca transformers, especifica o modelo pré-treinado t5-small e, em seguida, inicializa tanto o tokenizador (para converter texto em IDs numéricos) quanto o próprio modelo a partir dessa versão pré-treinada.\n",
        "\n"
      ],
      "metadata": {
        "id": "arCLeevDtRDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"translate English to German: Good morning\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\") #PyTorch\n",
        "inputs"
      ],
      "metadata": {
        "id": "aLgiypk5tFGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a286e53-5324-400a-922e-74874fc58dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[13959,  1566,    12,  2968,    10,  1804,  1379,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation_ids = model.generate(inputs.input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
        "print(translation_ids)\n",
        "translation_text = tokenizer.decode(translation_ids[0], skip_special_tokens=True)\n",
        "print(\"Translation:\", translation_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUzNOH9YtA63",
        "outputId": "abe9ceed-c99b-4702-a175-32b0940d72e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,  7756,    35, 20147,     1]])\n",
            "Translation: Guten Morgen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um tokenizador e modelo T5 para realizar tradução automática. Ele tokeniza o texto de entrada ('traduzir inglês para alemão: Bom dia'), gera IDs de tradução usando o modelo T5 pré-treinado e, em seguida, decodifica esses IDs de volta para um texto legível por humanos, finalmente imprimindo a frase traduzida em alemão."
      ],
      "metadata": {
        "id": "FYB7NB8RtpmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gRg6ayNWQ7L0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Atividade: Tradução de Máquina\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dFrOT_fRZtvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atividade: Tradução de Máquina\n",
        "\n",
        "Esta tarefa tem como objetivo que os alunos explorem e comparem a eficácia de diferentes ferramentas de tradução na conversão de textos que contêm terminologia específica de domínio de negócio. O aluno deve selecionar um texto-fonte curto (ate 5 paginas) rico em jargões técnicos de uma área de negócio, e em seguida, utilizar três ferramentas de tradução distintas, para traduzir esse texto para duas línguas de destino. A etapa crucial será a análise comparativa dos resultados, onde o foco deve estar na precisão terminológica dos termos de negócio, na coerência e na fluidez do texto traduzido. Finalmente, o aluno deverá elaborar um breve relatório que detalhe qual ferramenta demonstrou a melhor (e pior) performance na manutenção do significado e da precisão técnica do vocabulário especializado.\n",
        "\n",
        "Desafío:  Como um desafio extra, reflita sobre as diferenças entre traduzir um texto corrido e traduzir o conteúdo de uma apresentação de slides (PowerPoint ou Google Slides)."
      ],
      "metadata": {
        "id": "Ph1EibR4ZwLt"
      }
    }
  ]
}